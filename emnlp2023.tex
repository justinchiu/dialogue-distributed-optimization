% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Remove the "review" option to generate the final version.
\usepackage[review]{EMNLP2023}
%\usepackage{EMNLP2023}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% New packages
\usepackage{mystyle}
\usepackage{lipsum}
\usepackage{booktabs}
\usepackage{multirow}
%\usepackage{fontawesome}
\usepackage{amssymb}
\usepackage{listings}

\usepackage{courier}

\newcommand{\system}{SPC}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out.
% However, it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

\usepackage{tabu}
\newsavebox{\DialogueBox}

\newenvironment{Dialogue}[1][\small]{
    #1
    \def\arraystretch{1.3}
    \setlength\tabcolsep{7pt}
    \taburulecolor{lightgray}
    \vspace{.8em}
    \noindent
    \begin{tabu} to \columnwidth {|[2pt]lX}
}{
    \end{tabu}
    \vspace{.5em}
}

\newcommand{\Partner}[1]{Partner: & \UserUtt{#1} \\}
\newcommand{\AgentDo}[1]{
\\[-1.3em]
\multicolumn{2}{|[2pt]p{\linewidth}}{ 
\AgentAction{#1}
}
\\[.3em]
}
\newcommand{\AgentSay}[1]{Agent: & \AgentUtt{#1} \\}
\newcommand{\UserUtt}[1]{\textit{#1}}
\newcommand{\AgentUtt}[1]{\textit{#1}}
\newcommand{\AgentAction}[1]{\texttt{\small #1}}
\newcommand{\MetaAction}[1]{\texttt{\small \underline{#1}}}
\newcommand{\Exec}{\MetaAction{\textcolor{red}{We don't use eval anymore!}}\xspace}
\newcommand{\Salient}{\MetaAction{refer}\xspace}
\newcommand{\Revise}{\MetaAction{revise}\xspace}
\newcommand{\ReviseConstraint}{\MetaAction{reviseConstraint}\xspace}
\newcommand{\Describe}{\MetaAction{describe}\xspace}
\newcommand{\scExec}{\texttt{\scriptsize\underline{eval}}\xspace}
\newcommand{\scSalient}{\texttt{\scriptsize\underline{refer}}\xspace}
\newcommand{\scRevise}{\texttt{\scriptsize\underline{revise}}\xspace}
\newcommand{\Recover}{\MetaAction{recover}\xspace}
\newcommand{\Root}{\textit{root}}
\newcommand{\OurDataset}{SMCalFlow\xspace}


\newcommand{\justin}[1]{{{\textcolor{purple}{(Justin: #1)}}}}
\newcommand{\derek}[1]{{{\textcolor{blue}{(Derek: #1)}}}}
\newcommand{\wenting}[1]{{{\textcolor{orange}{(Wenting: #1)}}}}
\newcommand{\daniel}[1]{{{\textcolor{brown}{(Daniel: #1)}}}}
\newcommand{\srush}[1]{{{\textcolor{green}{(Sasha: #1)}}}}
\newcommand{\celine}[1]{{{\textcolor{blue}{(Celine: #1)}}}}

\AtBeginDocument{\def\sectionautorefname{Section}}%
\AtBeginDocument{\def\subsectionautorefname{Section}}%


% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\title{
Symbolic Planning and Codegen\\
for Decentralized Optimization through Dialogue
}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a seperate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

\author{
Justin T. Chiu  \\
Cornell Tech \\
\texttt{jtc257@cornell.edu}
\And
Wenting Zhao \\
Cornell University \\
\texttt{wz346@cornell.edu}
\And
Derek Chen \\
Columbia University \\
\texttt{dc3761@columbia.edu}
\AND
Saujas Vaduguru \\
Carnegie Mellon University \\
\texttt{svadugur@andrew.cmu.edu}
\And
Alexander M. Rush \\
Cornell Tech \\
\texttt{arush@cornell.edu}
}

\begin{document}
\maketitle

\begin{abstract}
TBD
\end{abstract}

\section{Introduction}
Our goal is to design robots that collaborate with humans to solve complex problems.
Humans often know the problem specification, but may have difficulty solving the problem itself.
Describing the problem in its entirety is expensive, requiring humans many words to convey.
Additionally, many parameters in the problem are extraneous (for example, only the max or top 5 elements of a list may be important).

Our goal is to minimize communication costs by iteratively requesting information, updating our beliefs, and repeating until a satisfactory solution is reached.
One approach is Bayesian optimization, which learns to maximize an unknown objective function,
e.g. $f(x) = \innerprod c x$, in as few evaluations of $f$ as possible.
A key assumption in Bayesian optimization is that $f$ is a black box with unknown structure.
Grey-box Bayesian optimization methods relax this assumption, improving sample complexity by taking advantage of structure in the optimization problem \citep{grey-box-bayesopt}.
Two examples of this are when the objective consists of composite functions \citep{astudillo2019bayesian} and multi-fidelity Bayesian optimization \citep{poloczek2016multiinformation,Zanjani_Foumani_2023}. (move to related work)

We extend grey-box Bayesian optimization by considering a new setting:
Agents can gather information about problem substructure directly, without assuming compositional structure.

We then extend grey-box Bayesian optimization to the dialogue setting by proposing a query language through which agents can request and receive information about the unknown optimization problem.
The query language is designed to be described concisely in natural language.

We propose a method, Language to Symbolic Optimization (LaSO) that collaborates with humans by requests information incrementally, decreasing human communication costs.
LaSO parses natural language responses to logical forms, which are used to inform a symbolic optimization algorithm that plans what to say next.

We evaluate LaSO on DialOp, a set of 3 decision-oriented dialogue tasks \citep{lin2023decision}.

\section{Problem setup}
The goal of decision-oriented dialogue (DOD) is to solve an optimization problem, such as
\begin{equation}
\label{eqn:obj}
\begin{array}{ll}
\mbox{maximize} & \innerprod{w}{x}\\
\mbox{subject to} & x \in F.
\end{array}
\end{equation}
Solving this problem is straightforward when both $w$ and $F$ are known,
and the problem size (dimension $\dim(w)$ and number of constraints $|F|$) is not too large.

We consider the setting where the parameters $c$, constraints $F$, and decision variables $x$ of the optimization problem are partitioned between dialogue participants, requiring them to exchange information (about $c$ and $F$) and make decisions  ($x$) collaboratively.
We take the perspective of one dialogue participant, who must communicate with other participants to solve the problem.

\section{Planning}
We first focus on the setting where the parameters $w\in\R^n$ are unknown, ignoring constraints $F$.
Our goal is to choose the most informative and utility-aware action at every turn in order to select a good terminal $x\in\mcX = \set{0,1}^n$.

We assume a fully factored prior over $w$, $p(w) = \prod_i p(w_i)$ with $w_i\sim N(0,1)$.

The partner model, $p(y | a,w)$, models responses $y$ to actions $a$ given parameters $w$.
The action space is extended to $a \in \mcX \cup \mathcal{Q}$, the union of the decision space and query space.
Responses are yes/no.

We plan by computing the knowledge gradient acquisition function \citep{kg}.
The knowledge gradient is an acquisition function with one-step lookahead.
It chooses the next action that gathers information which results in the largest improvement of a subsequent decision.
The subsequent decision is not restricted to previously observed values,
which is especially important in our setting where actions may not be in the decision space $\mcX$.
Formally, the knowledge gradient acquisition function is given by the following:
\begin{equation}
\label{eqn:kg}
\argmax_a \Es{w}{\sum_y p(y|a,w) \max_x \mu_{w|a,y}(x)}
- \max_{x'} \mu_w(x'),
\end{equation}
where $\mu_w(x) = \Es{w}{\langle w,x \rangle}$, the mean reward.
(INCOMPLETE: how to factor in costs?)

The acquisition function in equation \ref{eqn:kg} has an argmax over actions $a \in \mcX \cup \mathcal{Q}$.
In the worst case this means that we must solve the inner problem
$\max_x \mu_{w|a,y}(x)$ for each action $a$ and response $y$,
which requires calling a solver each time.
How to prevent computational blowup?

\section{Query language}


\bibliography{anthology,custom}
\bibliographystyle{acl_natbib}
\appendix

\section{EHIG}
Recent work has presented a unified perspective on BOpt to decision-theoretic entropies, proposing a framework that allows for the principled derivation of acquisition functions for custom tasks \citep{neiswanger2022generalizing}.
This is referred to as the expected $H_{l,A}$-information gain (EHIG),
where $H_{l,A}$ is a utility $l$ and action $A$ aware generalization of the Shannon entropy.
While this allows for unifying entropy search and BOpt, not sure if we can do anything with it yet.

\end{document}

