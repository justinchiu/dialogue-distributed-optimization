% This must be in the first 5 lines to tell arXiv to use pdfLaTeX, which is strongly recommended.
\pdfoutput=1
% In particular, the hyperref package requires pdfLaTeX in order to break URLs across lines.

\documentclass[11pt]{article}

% Remove the "review" option to generate the final version.
%\usepackage[review]{EMNLP2023}
\usepackage{EMNLP2023}

% Standard package includes
\usepackage{times}
\usepackage{latexsym}

% New packages
\usepackage{mystyle}
\usepackage{lipsum}
\usepackage{booktabs}
\usepackage{multirow}
%\usepackage{fontawesome}
\usepackage{amssymb}
\usepackage{listings}

\usepackage{courier}

\newcommand{\system}{SPC}

% For proper rendering and hyphenation of words containing Latin characters (including in bib files)
\usepackage[T1]{fontenc}
% For Vietnamese characters
% \usepackage[T5]{fontenc}
% See https://www.latex-project.org/help/documentation/encguide.pdf for other character sets

% This assumes your files are encoded as UTF8
\usepackage[utf8]{inputenc}

% This is not strictly necessary, and may be commented out.
% However, it will improve the layout of the manuscript,
% and will typically save some space.
\usepackage{microtype}

% This is also not strictly necessary, and may be commented out.
% However, it will improve the aesthetics of text in
% the typewriter font.
\usepackage{inconsolata}

\usepackage{tabu}
\newsavebox{\DialogueBox}

\newenvironment{Dialogue}[1][\small]{
    #1
    \def\arraystretch{1.3}
    \setlength\tabcolsep{7pt}
    \taburulecolor{lightgray}
    \vspace{.8em}
    \noindent
    \begin{tabu} to \columnwidth {|[2pt]lX}
}{
    \end{tabu}
    \vspace{.5em}
}

\newcommand{\Partner}[1]{Partner: & \UserUtt{#1} \\}
\newcommand{\AgentDo}[1]{
\\[-1.3em]
\multicolumn{2}{|[2pt]p{\linewidth}}{ 
\AgentAction{#1}
}
\\[.3em]
}
\newcommand{\AgentSay}[1]{Agent: & \AgentUtt{#1} \\}
\newcommand{\UserUtt}[1]{\textit{#1}}
\newcommand{\AgentUtt}[1]{\textit{#1}}
\newcommand{\AgentAction}[1]{\texttt{\small #1}}
\newcommand{\MetaAction}[1]{\texttt{\small \underline{#1}}}
\newcommand{\Exec}{\MetaAction{\textcolor{red}{We don't use eval anymore!}}\xspace}
\newcommand{\Salient}{\MetaAction{refer}\xspace}
\newcommand{\Revise}{\MetaAction{revise}\xspace}
\newcommand{\ReviseConstraint}{\MetaAction{reviseConstraint}\xspace}
\newcommand{\Describe}{\MetaAction{describe}\xspace}
\newcommand{\scExec}{\texttt{\scriptsize\underline{eval}}\xspace}
\newcommand{\scSalient}{\texttt{\scriptsize\underline{refer}}\xspace}
\newcommand{\scRevise}{\texttt{\scriptsize\underline{revise}}\xspace}
\newcommand{\Recover}{\MetaAction{recover}\xspace}
\newcommand{\Root}{\textit{root}}
\newcommand{\OurDataset}{SMCalFlow\xspace}


\newcommand{\justin}[1]{{{\textcolor{purple}{(Justin: #1)}}}}
\newcommand{\derek}[1]{{{\textcolor{blue}{(Derek: #1)}}}}
\newcommand{\wenting}[1]{{{\textcolor{orange}{(Wenting: #1)}}}}
\newcommand{\daniel}[1]{{{\textcolor{brown}{(Daniel: #1)}}}}
\newcommand{\srush}[1]{{{\textcolor{green}{(Sasha: #1)}}}}
\newcommand{\celine}[1]{{{\textcolor{blue}{(Celine: #1)}}}}

\AtBeginDocument{\def\sectionautorefname{Section}}%
\AtBeginDocument{\def\subsectionautorefname{Section}}%


% If the title and author information does not fit in the area allocated, uncomment the following
%
%\setlength\titlebox{<dim>}
%
% and set <dim> to something 5cm or larger.

\title{
Reasoning about Information in Dialogue:\\
Collaborative Decentralized Optimization
}

% Author information can be set in various styles:
% For several authors from the same institution:
% \author{Author 1 \and ... \and Author n \\
%         Address line \\ ... \\ Address line}
% if the names do not fit well on one line use
%         Author 1 \\ {\bf Author 2} \\ ... \\ {\bf Author n} \\
% For authors from different institutions:
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \And  ... \And
%         Author n \\ Address line \\ ... \\ Address line}
% To start a seperate ``row'' of authors use \AND, as in
% \author{Author 1 \\ Address line \\  ... \\ Address line
%         \AND
%         Author 2 \\ Address line \\ ... \\ Address line \And
%         Author 3 \\ Address line \\ ... \\ Address line}

\author{
Justin T. Chiu  \\
Cornell Tech \\
\texttt{jtc257@cornell.edu}
\And
Wenting Zhao \\
Cornell University \\
\texttt{wz346@cornell.edu}
\And
Derek Chen \\
Columbia University \\
\texttt{dc3761@columbia.edu}
\AND
Saujas Vaduguru \\
Carnegie Mellon University \\
\texttt{svadugur@andrew.cmu.edu}
\And
Alexander M. Rush \\
Cornell Tech \\
\texttt{arush@cornell.edu}
}

\begin{document}
\maketitle

\begin{abstract}
TBD
\end{abstract}

\section{Introduction}
Our goal is to design robots that collaborate with humans to solve complex problems.
Humans often know the problem specification, but may have difficulty solving the problem itself.
Describing the problem in its entirety is expensive, requiring humans many words to convey.
Additionally, many parameters in the problem are extraneous (for example, only the max or top-$k$ elements of a list may be important).

Minimizing communication costs is of utmost importance.
Human processing costs are 
Titeratively requesting information, updating our beliefs, and repeating until a satisfactory solution is reached.
One approach is Bayesian optimization, which learns to maximize an unknown objective function,
e.g. $f(x) = \innerprod c x$, in as few evaluations of $f$ as possible.
A key assumption in Bayesian optimization is that $f$ is a black box with unknown structure.
Grey-box Bayesian optimization methods relax this assumption, improving sample complexity by taking advantage of structure in the optimization problem \citep{grey-box-bayesopt}.

Two examples of this are when the objective consists of composite functions \citep{astudillo2019bayesian} and multi-fidelity Bayesian optimization \citep{poloczek2016multiinformation,Zanjani_Foumani_2023}. 
Preferential Bayesian optimization \citep{astudillo2023qeubo}. (move to related work)

We extend grey-box Bayesian optimization by considering a new setting:
Agents can gather information about problem substructure directly, without assuming compositional structure.

We then extend grey-box Bayesian optimization to the dialogue setting by proposing a query language through which agents can request and receive information about the unknown optimization problem.
The query language is designed to be described concisely in natural language.

We propose a method, Language to Symbolic Optimization (LSO) that collaborates with humans by requests information incrementally, decreasing human communication costs.
LSO parses natural language responses to logical forms, which are used to inform a symbolic optimization algorithm that plans what to say next.

We evaluate LSO on DialOp, a set of 3 decision-oriented dialogue tasks \citep{lin2023decision}.

\section{Related work}

\section{Decision-oriented dialogue}
The goal of decision-oriented dialogue (DOD) is to solve an optimization problem, such as
\begin{equation}
\label{eqn:obj}
\begin{array}{ll}
\mbox{maximize} & \innerprod{w}{x}\\
\mbox{subject to} & x \in C.
\end{array}
\end{equation}
Solving this problem is straightforward when both $w$ and $C$ are known,
and the problem size (dimension $\dim(w)$ and number of constraints $|C|$) is not too large.

We consider the setting where the parameters $w$, constraints $C$, and decision variables $x$ of the optimization problem are partitioned between dialogue participants, requiring them to exchange information (about $w$ and $F$)\footnote{Preference or reward learning is the setting where $w$ is unknown. Constraint acquisition is where $C$ is unknown.} and make decisions  ($x$) collaboratively.
We take the perspective of one dialogue participant, who must communicate with other participants to solve the problem.

Describe prior and observation model.
We assume a fully factored prior over $w$, $p(w) = \prod_i p(w_i)$ with $w_i\sim N(\mu_0,1)$.
The response model, $p(y | a,w)$, models responses $y$ to actions $a$ given parameters $w$.
The action space is extended to $a \in \mcX \cup \mathcal{Q}$, the union of the decision space and query space.
Responses are yes/no or categorical.

\section{Planning}
We first focus on the setting where the parameters $w\in\R^n$ are unknown, ignoring constraints $C$.
Our goal is to choose the most informative and utility-aware action at every turn in order to select a good terminal $x\in\mcX = \set{0,1}^n$.

We plan by optimizing the knowledge gradient acquisition function \citep{kg}.
The knowledge gradient is an acquisition function with one-step lookahead.
It chooses the next action that gathers information which results in the largest improvement of a subsequent decision.
The subsequent decision is not restricted to previously observed values,
which is especially important in our setting where actions may not be in the decision space $\mcX$.
Formally, the knowledge gradient acquisition function is given by the following:
\begin{equation}
\label{eqn:kg}
\begin{aligned}
\argmax_a \; & \Es{y|h,a}{\max_x \mu_{w|h,a,y}(x)}\\
&- \max_{x} \mu_{w|h}(x),
\end{aligned}
\end{equation}
where $\mu_w(x) = \Es{w}{\langle w,x \rangle}$, the mean reward.
Costs: subtract (textbook) or divide (cost-aware multi-fidelity BO)?

The acquisition function in equation \ref{eqn:kg} has an argmax over actions $a \in \mcX \cup \mathcal{Q}$.
In the worst case this means that we must solve the inner problem
$\max_x \mu_{w|a,y}(x)$ for each action $a$ and response $y$,
which requires calling a solver each time.
How to prevent computational blowup?
Common to sample $y$, but that isn't enough.
$x$ is also discrete. Is this easy in weighted linear sum assignment problems?

\section{Query language}
This section discusses the query language $\mathcal{Q}$ and observation model.
Bradley-Terry and Plackett-Luce for pairwise and ranking comparisons respectively.

\begin{equation}
p(x \succ y | w)= \frac{e^{w_x}}{e^{w_x} + e^{w_y}}
\end{equation}

\section{8/20: Questions for Xinran}
\begin{enumerate}
    \item Is there a way to not call the solver $|a|*|y|$ times? Some problem-dependent linear optimization trick?
    \item Is there a principled way of assigning cost to actions? Learned from static data, since we can estimate the utility of any given action? Can be a very primitive kind of learning, e.g. linear function of size($a$).
\end{enumerate}

% good baseline: normal BO w/ $a \in \mcX$
% not much cost learnign in BO. cost-aware multi-fidelity. cost model is simple from empirical study. typically rough empirical cost model would work
% we have offline data! 
% can we estimate how important cost is?

are there other acquisition functions that are 1-step lookahead but aren't intractable like KG?
can still do EI w/ 1-step lookahead. (pointers to lit would be helpful!)
lit: http://proceedings.mlr.press/v124/lee20a/lee20a.pdf

\bibliography{anthology,custom}
\bibliographystyle{acl_natbib}
\appendix

\section{Posterior inference}
In this section we derive the posteriors for the Matching problem.
Let $y_i = \langle w, x_i\rangle$, with
$$p(y_i|w,x) = N\left(\langle w,x_i\rangle, \sqrt{w^\top \text{diag}(x_i)w}\right).$$
Given a prior $p(w) = N(\mu_0, \sigma_0 I)$, and a set of observations $\set{y_i}$, we can compute the posterior
\begin{align*}12
p(w | y, x) &\propto \prod_i p(y_i | w,x) p(w)\\
&= \frac{1}{\sigma I} e^{-1/2(y-\mu)^\top \Sigma^{-1}(y-\mu)}
    \frac{1}{\sigma_0I} e^{-1/2 (w-)}
\end{align*}

\section{EHIG}
Recent work has presented a unified perspective on BOpt to decision-theoretic entropies, proposing a framework that allows for the principled derivation of acquisition functions for custom tasks \citep{neiswanger2022generalizing}.
This is referred to as the expected $H_{l,A}$-information gain (EHIG),
where $H_{l,A}$ is a utility $l$ and action $A$ aware generalization of the Shannon entropy.
While this allows for unifying entropy search and BOpt, not sure if we can do anything with it yet.

\end{document}

