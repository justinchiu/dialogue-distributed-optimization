%%%%%%%% ICML 2023 EXAMPLE LATEX SUBMISSION FILE %%%%%%%%%%%%%%%%%

\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2023} with \usepackage[nohyperref]{icml2023} above.
\usepackage{hyperref}


% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
%\usepackage{icml2023}

% If accepted, instead use the following line for the camera-ready submission:
\usepackage[accepted]{icml2023}

% For theorems and such
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{amsthm}

% justin's macros
\usepackage{mystyle}

% if you use cleveref..
\usepackage[capitalize,noabbrev]{cleveref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% THEOREMS
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{assumption}[theorem]{Assumption}
\theoremstyle{remark}
\newtheorem{remark}[theorem]{Remark}

% Todonotes is useful during development; simply uncomment the next line
%    and comment out the line below the next line to turn off comments
%\usepackage[disable,textsize=tiny]{todonotes}
\usepackage[textsize=tiny]{todonotes}


% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{Submission and Formatting Instructions for ICML 2023}

\begin{document}

\twocolumn[
\icmltitle{Submission and Formatting Instructions for \\
           International Conference on Machine Learning (ICML 2023)}

% It is OKAY to include author information, even for blind
% submissions: the style file will automatically remove it for you
% unless you've provided the [accepted] option to the icml2023
% package.

% List of affiliations: The first argument should be a (short)
% identifier you will use later to specify author affiliations
% Academic affiliations should list Department, University, City, Region, Country
% Industry affiliations should list Company, City, Region, Country

% You can specify symbols, otherwise they are numbered in order.
% Ideally, you should not use this facility. Affiliations will be numbered
% in order of appearance and this is the preferred way.
\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Justin T. Chiu}{ct}
\icmlauthor{Wenting Zhao}{ct}
\icmlauthor{Derek Chen}{cu}
\icmlauthor{Alexander M. Rush}{ct}
\end{icmlauthorlist}

\icmlaffiliation{ct}{Cornell Tech}
\icmlaffiliation{cu}{Columbia University}

\icmlcorrespondingauthor{Justin T. Chiu}{chiu.justin.t@gmail.com}

% You may provide any keywords that you
% find helpful for describing your paper; these are used to populate
% the "keywords" metadata in the PDF but will not be shown in the document
\icmlkeywords{Machine Learning, ICML}

\vskip 0.3in
]

% this must go after the closing bracket ] following \twocolumn[ ...

% This command actually creates the footnote in the first column
% listing the affiliations and the copyright notice.
% The command takes one argument, which is text to display at the start of the footnote.
% The \icmlEqualContribution command is standard text for equal contribution.
% Remove it (just {}) if you do not need this facility.

\printAffiliationsAndNotice{}  % leave blank if no need to mention equal contribution
%\printAffiliationsAndNotice{\icmlEqualContribution} % otherwise use the standard text.

\begin{abstract}
Collaborative dialogue agents must balance communicative efficiency with task process for effective collaboration.
We design a system that strategically asks questions while minimizing communication costs via symbolic planning.
Our system consists of a reader, planner, and writer:
The reader maps language to logical forms
which inform the symbolic planner's next decision,
represented as a logical form.
The writer then converts the logical form to a response,
taking into account any information not captured by the reader.
Results on DialOp, negotiation in Deal-or-no-Deal.
\end{abstract}

\section{Introduction}

Our goal is to design robots that collaborate with humans to solve complex problems.
Humans often know the problem specification, but may have difficulty solving the problem itself.
Describing the problem in its entirety is expensive, requiring humans many words to convey.
The marginal improvement from full information may not be worth the communicative cost.

Minimizing communication costs is of utmost importance.
Human processing costs are 
Titeratively requesting information, updating our beliefs, and repeating until a satisfactory solution is reached.
One approach is Bayesian optimization, which learns to maximize an unknown objective function,
e.g. $f(x) = \innerprod c x$, in as few evaluations of $f$ as possible.
A key assumption in Bayesian optimization is that $f$ is a black box with unknown structure.
Grey-box Bayesian optimization methods relax this assumption, improving sample complexity by taking advantage of structure in the optimization problem \citep{grey-box-bayesopt}.

Two examples of this are when the objective consists of composite functions \citep{astudillo2019bayesian} and multi-fidelity Bayesian optimization \citep{poloczek2016multiinformation,Zanjani_Foumani_2023}. 
Preferential Bayesian optimization \citep{astudillo2023qeubo}. (move to related work)

We extend grey-box Bayesian optimization by considering a new setting:
Agents can gather information about problem substructure directly, without assuming compositional structure.

We then extend grey-box Bayesian optimization to the dialogue setting by proposing a query language through which agents can request and receive information about the unknown optimization problem.
The query language is designed to be described concisely in natural language.

We propose a method, Language to Symbolic Optimization (LSO) that collaborates with humans by requests information incrementally, decreasing human communication costs.
LSO parses natural language responses to logical forms, which are used to inform a symbolic optimization algorithm that plans what to say next.

We evaluate LSO on DialOp, a set of 3 decision-oriented dialogue tasks \citep{lin2023decision}.

\section{Related work}

\section{Decision-oriented dialogue}
The goal of decision-oriented dialogue (DOD) is to solve an optimization problem, such as
\begin{equation}
\label{eqn:obj}
\begin{array}{ll}
\mbox{maximize} & \innerprod{w}{x}\\
\mbox{subject to} & x \in C.
\end{array}
\end{equation}
Solving this problem is straightforward when both $w$ and $C$ are known,
and the problem size (dimension $\dim(w)$ and number of constraints $|C|$) is not too large.

We consider the setting where the parameters $w$, constraints $C$, and decision variables $x$ of the optimization problem are partitioned between dialogue participants, requiring them to exchange information (about $w$ and $F$)\footnote{Preference or reward learning is the setting where $w$ is unknown. Constraint acquisition is where $C$ is unknown.} and make decisions  ($x$) collaboratively.
We take the perspective of one dialogue participant, who must communicate with other participants to solve the problem.

Describe prior and observation model.
We assume a fully factored prior over $w$, $p(w) = \prod_i p(w_i)$ with $w_i\sim N(\mu_0,1)$.
The response model, $p(y | a,w)$, models responses $y$ to actions $a$ given parameters $w$.
The action space is extended to $a \in \mcX \cup \mathcal{Q}$, the union of the decision space and query space.
Responses are yes/no or categorical.

\section{Planning}
We first focus on the setting where the parameters $w\in\R^n$ are unknown, ignoring constraints $C$.
Our goal is to choose the most informative and utility-aware action at every turn in order to select a good terminal $x\in\mcX = \set{0,1}^n$.

We plan by optimizing the knowledge gradient acquisition function \citep{kg}.
The knowledge gradient is an acquisition function with one-step lookahead.
It chooses the next action that gathers information which results in the largest improvement of a subsequent decision.
The subsequent decision is not restricted to previously observed values,
which is especially important in our setting where actions may not be in the decision space $\mcX$.
Formally, the knowledge gradient acquisition function is given by the following:
\begin{equation}
\label{eqn:kg}
\begin{aligned}
\argmax_a \; & \Es{y|h,a}{\max_x \mu_{w|h,a,y}(x)}\\
&- \max_{x} \mu_{w|h}(x),
\end{aligned}
\end{equation}
where $\mu_w(x) = \Es{w}{\langle w,x \rangle}$, the mean reward.
Costs: subtract (textbook) or divide (cost-aware multi-fidelity BO)?

The acquisition function in equation \ref{eqn:kg} has an argmax over actions $a \in \mcX \cup \mathcal{Q}$.
In the worst case this means that we must solve the inner problem
$\max_x \mu_{w|a,y}(x)$ for each action $a$ and response $y$,
which requires calling a solver each time.
How to prevent computational blowup?
Common to sample $y$, but that isn't enough.
$x$ is also discrete. Is this easy in weighted linear sum assignment problems?

\section{Query language}
This section discusses the query language $\mathcal{Q}$ and observation model.
Bradley-Terry and Plackett-Luce for pairwise and ranking comparisons respectively.

\begin{equation}
p(x \succ y | w)= \frac{e^{w_x}}{e^{w_x} + e^{w_y}}
\end{equation}

\section{Questions}
\begin{enumerate}
    \item Is there a way to not call the solver $|a|*|y|$ times? Some problem-dependent linear optimization trick?
    \item Is there a principled way of assigning cost to actions? Learned from static data, since we can estimate the utility of any given action? Can be a very primitive kind of learning, e.g. linear function of size($a$).
\end{enumerate}

% good baseline: normal BO w/ $a \in \mcX$
% not much cost learnign in BO. cost-aware multi-fidelity. cost model is simple from empirical study. typically rough empirical cost model would work
% we have offline data! 
% can we estimate how important cost is?

are there other acquisition functions that are 1-step lookahead but aren't intractable like KG?
can still do EI w/ 1-step lookahead. (pointers to lit would be helpful!)
lit: http://proceedings.mlr.press/v124/lee20a/lee20a.pdf


\bibliography{soap}
\bibliographystyle{icml2023}


% Acknowledgements should only appear in the accepted version.
\section*{Acknowledgements}
People


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% APPENDIX
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\appendix
\onecolumn

\section{EHIG}
Recent work has presented a unified perspective on BOpt to decision-theoretic entropies, proposing a framework that allows for the principled derivation of acquisition functions for custom tasks \citep{neiswanger2022generalizing}.
This is referred to as the expected $H_{l,A}$-information gain (EHIG),
where $H_{l,A}$ is a utility $l$ and action $A$ aware generalization of the Shannon entropy.
While this allows for unifying entropy search and BOpt, not sure if we can do anything with it yet.


\end{document}


% This document was modified from the file originally made available by
% Pat Langley and Andrea Danyluk for ICML-2K. This version was created
% by Iain Murray in 2018, and modified by Alexandre Bouchard in
% 2019 and 2021 and by Csaba Szepesvari, Gang Niu and Sivan Sabato in 2022.
% Modified again in 2023 by Sivan Sabato and Jonathan Scarlett.
% Previous contributors include Dan Roy, Lise Getoor and Tobias
% Scheffer, which was slightly modified from the 2010 version by
% Thorsten Joachims & Johannes Fuernkranz, slightly modified from the
% 2009 version by Kiri Wagstaff and Sam Roweis's 2008 version, which is
% slightly modified from Prasad Tadepalli's 2007 version which is a
% lightly changed version of the previous year's version by Andrew
% Moore, which was in turn edited from those of Kristian Kersting and
% Codrina Lauth. Alex Smola contributed to the algorithmic style files.
